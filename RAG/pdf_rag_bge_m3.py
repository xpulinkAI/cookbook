"""
PDF RAG ç³»ç»Ÿ - ä½¿ç”¨ BGE-M3 Embedding + LiteLLM

æœ¬è„šæœ¬å±•ç¤ºå¦‚ä½•ä½¿ç”¨ XPULink å¹³å°æ‰˜ç®¡çš„æ¨¡å‹æ„å»º RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ç³»ç»Ÿã€‚
ä½¿ç”¨ LiteLLM ä¼˜é›…åœ°æ”¯æŒè‡ªå®šä¹‰ OpenAI é£æ ¼ APIï¼Œæ— éœ€ hack æˆ–ç»•è¿‡éªŒè¯ã€‚

åŠŸèƒ½ç‰¹æ€§ï¼š
- åŠ è½½å’Œå¤„ç† PDF æ–‡æ¡£
- ä½¿ç”¨ BGE-M3 Embedding æ¨¡å‹è¿›è¡Œæ–‡æ¡£å‘é‡åŒ–
- ä½¿ç”¨ LiteLLM æ”¯æŒè‡ªå®šä¹‰ LLMï¼ˆqwen3-32bï¼‰
- æ„å»ºå‘é‡ç´¢å¼•å®ç°é«˜æ•ˆæ£€ç´¢
- åŸºäºæ£€ç´¢ç»“æœç”Ÿæˆæ™ºèƒ½å›ç­”
- é¢„æµ‹å‘é‡æ•°æ®åº“å¤§å°
- äº¤äº’å¼æŸ¥è¯¢ç•Œé¢
- è‡ªåŠ¨é‡è¯•æœºåˆ¶å¤„ç†ç½‘ç»œé—®é¢˜

æŠ€æœ¯æ ˆï¼š
- LlamaIndex: RAG æ¡†æ¶
- LiteLLM: ç»Ÿä¸€ LLM æ¥å£ï¼ˆæ”¯æŒè‡ªå®šä¹‰ APIï¼‰
- BGE-M3: å¤šè¯­è¨€ Embedding æ¨¡å‹
- Qwen3-32B: å¤§è¯­è¨€æ¨¡å‹

ä½œè€…: XPULink
æ—¥æœŸ: 2025-01
"""

import os
import json
import requests
import time
from typing import List, Optional, Dict, Any
from dotenv import load_dotenv
from pydantic import Field, PrivateAttr

from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings
from llama_index.core.embeddings import BaseEmbedding
from llama_index.llms.litellm import LiteLLM


class BGEM3Embedding(BaseEmbedding):
    """BGE-M3 Embedding æ¨¡å‹å®ç°ï¼ˆåŸºäº OpenAI å…¼å®¹ APIï¼‰"""

    api_base: str = Field(default="https://xpulink.net/v1", description="XPULink API åŸºç¡€åœ°å€")
    api_key: Optional[str] = Field(default=None, description="API å¯†é’¥")
    model_name: str = Field(default="bge-m3", description="æ¨¡å‹åç§°")
    embed_batch_size: int = Field(default=10, description="æ‰¹å¤„ç†å¤§å°")

    def __init__(
        self,
        api_base: str = "https://xpulink.net/v1",
        api_key: Optional[str] = "",
        model: str = "bge-m3",
        embed_batch_size: int = 10,
        **kwargs
    ) -> None:
        """
        åˆå§‹åŒ– BGE-M3 Embedding æ¨¡å‹

        Args:
            api_base: XPULink API åŸºç¡€åœ°å€
            api_key: API å¯†é’¥ï¼ˆä»ç¯å¢ƒå˜é‡è·å–ï¼‰
            model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸º bge-m3
            embed_batch_size: æ‰¹å¤„ç†å¤§å°
        """
        # å¤„ç† API key
        if api_key is None:
            api_key = os.getenv("XPU_API_KEY")

        if not api_key:
            raise ValueError("éœ€è¦æä¾› API Key")

        # å¤„ç† api_base
        api_base = api_base.rstrip('/')

        # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°ï¼Œä¼ é€’æ‰€æœ‰å‚æ•°
        super().__init__(
            api_base=api_base,
            api_key=api_key,
            model_name=model,
            embed_batch_size=embed_batch_size,
            **kwargs
        )

    def _call_api(self, texts: List[str], max_retries: int = 3) -> List[List[float]]:
        """
        è°ƒç”¨ XPULink API è·å– embeddingsï¼Œå¸¦é‡è¯•æœºåˆ¶

        Args:
            texts: è¦å¤„ç†çš„æ–‡æœ¬åˆ—è¡¨
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }

        data = {
            'model': self.model_name,
            'input': texts
        }

        last_exception = None

        for attempt in range(max_retries):
            try:
                response = requests.post(
                    f"{self.api_base}/embeddings",
                    headers=headers,
                    json=data,
                    timeout=1000
                )
                response.raise_for_status()

                result = response.json()
                if result.get('data'):
                    return [item['embedding'] for item in result['data']]
                else:
                    raise Exception(f"API è¿”å›æ ¼å¼é”™è¯¯: {result}")

            except (requests.exceptions.RequestException,
                    requests.exceptions.ChunkedEncodingError,
                    requests.exceptions.ConnectionError) as e:
                last_exception = e

                if attempt < max_retries - 1:
                    # æŒ‡æ•°é€€é¿: ç­‰å¾… 2^attempt ç§’
                    wait_time = 2 ** attempt
                    print(f"âš ï¸  è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}), {wait_time}ç§’åé‡è¯•...")
                    print(f"   é”™è¯¯: {str(e)}")
                    time.sleep(wait_time)
                else:
                    # æœ€åä¸€æ¬¡å°è¯•ä¹Ÿå¤±è´¥äº†
                    raise Exception(f"API è¯·æ±‚å¤±è´¥ (å·²é‡è¯•{max_retries}æ¬¡): {str(e)}")

        # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        raise Exception(f"API è¯·æ±‚å¤±è´¥: {str(last_exception)}")

    def _get_query_embedding(self, query: str) -> List[float]:
        """è·å–å•ä¸ªæŸ¥è¯¢çš„ embedding"""
        embeddings = self._call_api([query])
        return embeddings[0] if embeddings else []

    def _get_text_embedding(self, text: str) -> List[float]:
        """è·å–å•ä¸ªæ–‡æœ¬çš„ embedding"""
        embeddings = self._call_api([text])
        return embeddings[0] if embeddings else []

    def _get_text_embeddings(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡è·å–æ–‡æœ¬çš„ embeddings"""
        all_embeddings = []

        # åˆ†æ‰¹å¤„ç†
        for i in range(0, len(texts), self.embed_batch_size):
            batch = texts[i:i + self.embed_batch_size]
            batch_embeddings = self._call_api(batch)
            all_embeddings.extend(batch_embeddings)

            if i + self.embed_batch_size < len(texts):
                print(f"å·²å¤„ç† {i + len(batch)}/{len(texts)} ä¸ªæ–‡æœ¬ç‰‡æ®µ")

        return all_embeddings

    async def _aget_query_embedding(self, query: str) -> List[float]:
        """å¼‚æ­¥è·å–æŸ¥è¯¢ embeddingï¼ˆå›é€€åˆ°åŒæ­¥æ–¹æ³•ï¼‰"""
        return self._get_query_embedding(query)


def estimate_vector_db_size(documents, embedding_dim=1024, dtype_bytes=4) -> Dict[str, Any]:
    """
    é¢„æµ‹å‘é‡æ•°æ®åº“çš„å­˜å‚¨å¤§å°

    Args:
        documents: æ–‡æ¡£åˆ—è¡¨
        embedding_dim: å‘é‡ç»´åº¦ï¼ˆBGE-M3 é»˜è®¤ä¸º 1024ï¼‰
        dtype_bytes: æ•°æ®ç±»å‹å­—èŠ‚æ•°ï¼ˆfloat32 ä¸º 4 å­—èŠ‚ï¼‰

    Returns:
        dict: åŒ…å«å„é¡¹å¤§å°ç»Ÿè®¡çš„å­—å…¸
    """
    if not documents:
        return {
            'error': 'æ²¡æœ‰æ–‡æ¡£å¯ä¾›åˆ†æ',
            'total_size_mb': 0
        }

    # ä¼°ç®—æ–‡æ¡£è¢«åˆ†å—çš„æ•°é‡
    # LlamaIndex é»˜è®¤ chunk_size=1024, chunk_overlap=20
    chunk_size = 1024
    chunk_overlap = 20
    effective_chunk_size = chunk_size - chunk_overlap

    total_chars = sum(len(doc.text) for doc in documents)
    estimated_chunks = max(1, total_chars // effective_chunk_size)

    # è®¡ç®—å‘é‡å­˜å‚¨å¤§å°
    # æ¯ä¸ª chunk éœ€è¦ä¸€ä¸ª embedding å‘é‡
    vector_size_bytes = estimated_chunks * embedding_dim * dtype_bytes
    vector_size_mb = vector_size_bytes / (1024 * 1024)

    # è®¡ç®—æ–‡æœ¬å­˜å‚¨å¤§å°ï¼ˆUTF-8 ç¼–ç ï¼Œçº¦æ¯å­—ç¬¦ 2-3 å­—èŠ‚ï¼Œè¿™é‡Œå– 2.5ï¼‰
    text_size_bytes = total_chars * 2.5
    text_size_mb = text_size_bytes / (1024 * 1024)

    # è®¡ç®—å…ƒæ•°æ®å­˜å‚¨å¤§å°ï¼ˆä¼°ç®—æ¯ä¸ª chunk çº¦ 500 å­—èŠ‚å…ƒæ•°æ®ï¼‰
    metadata_size_bytes = estimated_chunks * 500
    metadata_size_mb = metadata_size_bytes / (1024 * 1024)

    # ç´¢å¼•å¼€é”€ï¼ˆFAISS æˆ–å…¶ä»–ç´¢å¼•ç»“æ„ï¼Œçº¦ä¸ºå‘é‡å¤§å°çš„ 20-30%ï¼‰
    index_overhead_factor = 0.25
    index_overhead_mb = vector_size_mb * index_overhead_factor

    # æ€»å¤§å°
    total_size_mb = vector_size_mb + text_size_mb + metadata_size_mb + index_overhead_mb

    return {
        'total_documents': len(documents),
        'total_characters': total_chars,
        'estimated_chunks': estimated_chunks,
        'embedding_dimension': embedding_dim,
        'vector_storage_mb': round(vector_size_mb, 2),
        'text_storage_mb': round(text_size_mb, 2),
        'metadata_storage_mb': round(metadata_size_mb, 2),
        'index_overhead_mb': round(index_overhead_mb, 2),
        'total_size_mb': round(total_size_mb, 2),
        'total_size_gb': round(total_size_mb / 1024, 3)
    }


def print_size_estimation(estimation: Dict[str, Any]) -> None:
    """æ‰“å°æ ¼å¼åŒ–çš„å¤§å°é¢„æµ‹ç»“æœ"""
    if 'error' in estimation:
        print(f"âŒ {estimation['error']}")
        return

    print("=" * 60)
    print("ğŸ“Š å‘é‡æ•°æ®åº“å¤§å°é¢„æµ‹")
    print("=" * 60)
    print(f"\nğŸ“„ æ–‡æ¡£ç»Ÿè®¡:")
    print(f"  - æ–‡æ¡£æ•°é‡: {estimation['total_documents']}")
    print(f"  - æ€»å­—ç¬¦æ•°: {estimation['total_characters']:,}")
    print(f"  - é¢„è®¡åˆ†å—æ•°: {estimation['estimated_chunks']:,}")
    print(f"  - å‘é‡ç»´åº¦: {estimation['embedding_dimension']}")

    print(f"\nğŸ’¾ å­˜å‚¨ç©ºé—´é¢„æµ‹:")
    print(f"  - å‘é‡å­˜å‚¨: {estimation['vector_storage_mb']:,.2f} MB")
    print(f"  - æ–‡æœ¬å­˜å‚¨: {estimation['text_storage_mb']:,.2f} MB")
    print(f"  - å…ƒæ•°æ®å­˜å‚¨: {estimation['metadata_storage_mb']:,.2f} MB")
    print(f"  - ç´¢å¼•å¼€é”€: {estimation['index_overhead_mb']:,.2f} MB")

    print(f"\nğŸ“¦ æ€»è®¡:")
    print(f"  - æ€»å¤§å°: {estimation['total_size_mb']:,.2f} MB ({estimation['total_size_gb']:.3f} GB)")

    # æ·»åŠ å»ºè®®
    total_mb = estimation['total_size_mb']
    print(f"\nğŸ’¡ å»ºè®®:")
    if total_mb < 100:
        print("  âœ… å†…å­˜å ç”¨è¾ƒå°ï¼Œå¯ä»¥è½»æ¾åœ¨å†…å­˜ä¸­å¤„ç†")
    elif total_mb < 1000:
        print("  âš ï¸  å†…å­˜å ç”¨é€‚ä¸­ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„å¯ç”¨å†…å­˜")
    else:
        print("  âš ï¸  å†…å­˜å ç”¨è¾ƒå¤§ï¼Œå»ºè®®è€ƒè™‘:")
        print("     - ä½¿ç”¨æŒä¹…åŒ–å‘é‡æ•°æ®åº“ï¼ˆå¦‚ Chromaã€Weaviateï¼‰")
        print("     - åˆ†æ‰¹å¤„ç†æ–‡æ¡£")
        print("     - ä½¿ç”¨æ›´å¼ºå¤§çš„æœåŠ¡å™¨")

    print("=" * 60)


def load_documents(data_dir: str = "./data/") -> Optional[List]:
    """
    åŠ è½½ PDF æ–‡æ¡£

    Args:
        data_dir: æ•°æ®ç›®å½•è·¯å¾„

    Returns:
        æ–‡æ¡£åˆ—è¡¨ï¼Œå¦‚æœåŠ è½½å¤±è´¥è¿”å› None
    """
    # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
    if not os.path.exists(data_dir):
        os.makedirs(data_dir)
        print(f"ğŸ“ å·²åˆ›å»ºæ•°æ®ç›®å½•: {data_dir}")
        print(f"âš ï¸  è¯·å°† PDF æ–‡ä»¶æ”¾å…¥æ­¤ç›®å½•")
        return None

    # åŠ è½½æ–‡æ¡£
    try:
        documents = SimpleDirectoryReader(
            input_dir=data_dir,
            required_exts=[".pdf"]
        ).load_data()

        if documents:
            print(f"âœ… æˆåŠŸåŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£ç‰‡æ®µ")
            print(f"\nğŸ“„ ç¬¬ä¸€ä¸ªæ–‡æ¡£ç‰‡æ®µé¢„è§ˆ:")
            print(f"  - é•¿åº¦: {len(documents[0].text)} å­—ç¬¦")
            print(f"  - å†…å®¹é¢„è§ˆ: {documents[0].text[:200]}...")
            return documents
        else:
            print(f"âš ï¸  æœªåœ¨ {data_dir} ç›®å½•ä¸­æ‰¾åˆ° PDF æ–‡ä»¶")
            print("è¯·æ·»åŠ  PDF æ–‡ä»¶åé‡è¯•")
            return None

    except Exception as e:
        print(f"âŒ åŠ è½½æ–‡æ¡£å¤±è´¥: {str(e)}")
        return None


def setup_rag_system(api_key: Optional[str] = None):
    """
    è®¾ç½® RAG ç³»ç»Ÿé…ç½®

    Args:
        api_key: XPU API Keyï¼Œå¦‚æœä¸æä¾›åˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
    """
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()

    # æ£€æŸ¥ API Key
    api_key = api_key or os.getenv('XPU_API_KEY')
    if not api_key:
        raise ValueError("âŒ æœªæ‰¾åˆ° XPU_API_KEYã€‚è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®æˆ–ä½œä¸ºå‚æ•°ä¼ å…¥ã€‚")

    print("âœ… æ‰¾åˆ° XPU_API_KEY ç¯å¢ƒå˜é‡")

    # é…ç½® BGE-M3 Embedding æ¨¡å‹
    Settings.embed_model = BGEM3Embedding(
        api_base="https://www.xpulink.net/v1",
        model="bge-m3:latest",
        embed_batch_size=5  # å‡å°‘æ‰¹æ¬¡å¤§å°æé«˜ç¨³å®šæ€§
    )

    # é…ç½® LLMï¼ˆä½¿ç”¨ LiteLLM - ä¼˜é›…åœ°æ”¯æŒè‡ªå®šä¹‰æ¨¡å‹ï¼‰
    Settings.llm = LiteLLM(
        model="openai/qwen3-32b",  # LiteLLM æ ¼å¼: provider/model
        api_key=api_key,
        api_base="https://www.xpulink.net/v1",
        temperature=0.7,
        custom_llm_provider="openai"  # æŒ‡å®šè¿™æ˜¯ OpenAI é£æ ¼çš„ API
    )

    print("âœ… LlamaIndex é…ç½®å®Œæˆï¼ˆä½¿ç”¨ LiteLLMï¼‰")
    print(f"  - Embedding æ¨¡å‹: {Settings.embed_model.model_name}")
    print(f"  - LLM æ¨¡å‹: qwen3-32b (via LiteLLM)")
    print(f"  - API ç«¯ç‚¹: https://www.xpulink.net/v1")


def build_index(documents: List, show_estimation: bool = True):
    """
    æ„å»ºå‘é‡ç´¢å¼•

    Args:
        documents: æ–‡æ¡£åˆ—è¡¨
        show_estimation: æ˜¯å¦æ˜¾ç¤ºå¤§å°é¢„æµ‹

    Returns:
        VectorStoreIndex å¯¹è±¡
    """
    if not documents:
        raise ValueError("æ–‡æ¡£åˆ—è¡¨ä¸ºç©º")

    # æ˜¾ç¤ºé¢„æµ‹ä¿¡æ¯
    if show_estimation:
        print("ğŸ”„ æ­£åœ¨åˆ†ææ–‡æ¡£å¹¶é¢„æµ‹å‘é‡æ•°æ®åº“å¤§å°...\n")
        estimation = estimate_vector_db_size(documents)
        print_size_estimation(estimation)
        print()

    print("ğŸ”„ å¼€å§‹æ„å»ºå‘é‡ç´¢å¼•...")
    print("   è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´ï¼Œå–å†³äºæ–‡æ¡£å¤§å°\n")

    try:
        # æ„å»ºå‘é‡ç´¢å¼•
        index = VectorStoreIndex.from_documents(
            documents,
            show_progress=True
        )

        print("\nâœ… å‘é‡ç´¢å¼•æ„å»ºå®Œæˆï¼")
        print("   ç°åœ¨å¯ä»¥è¿›è¡Œæ–‡æ¡£æŸ¥è¯¢äº†")

        return index

    except Exception as e:
        print(f"âŒ æ„å»ºç´¢å¼•å¤±è´¥: {str(e)}")
        raise


def create_query_engine(index, similarity_top_k: int = 3, response_mode: str = "compact"):
    """
    åˆ›å»ºæŸ¥è¯¢å¼•æ“

    Args:
        index: VectorStoreIndex å¯¹è±¡
        similarity_top_k: è¿”å›æœ€ç›¸ä¼¼çš„ K ä¸ªç‰‡æ®µ
        response_mode: å“åº”æ¨¡å¼ (compact/tree_summarize/refine)

    Returns:
        æŸ¥è¯¢å¼•æ“å¯¹è±¡
    """
    query_engine = index.as_query_engine(
        similarity_top_k=similarity_top_k,
        response_mode=response_mode
    )

    print("âœ… æŸ¥è¯¢å¼•æ“åˆ›å»ºå®Œæˆ")
    print(f"  - æ£€ç´¢ç‰‡æ®µæ•°: {similarity_top_k}")
    print(f"  - å“åº”æ¨¡å¼: {response_mode}")

    return query_engine


def run_example_queries(query_engine):
    """è¿è¡Œç¤ºä¾‹æŸ¥è¯¢"""
    print("\n" + "=" * 60)
    print("ğŸ“ è¿è¡Œç¤ºä¾‹æŸ¥è¯¢")
    print("=" * 60)

    example_queries = [
        "æ–‡æ¡£çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ",
        "è¯·æ€»ç»“æ–‡æ¡£ä¸­çš„å…³é”®è¦ç‚¹"
    ]

    for i, query in enumerate(example_queries, 1):
        print(f"\nğŸ” ç¤ºä¾‹æŸ¥è¯¢ {i}: {query}\n")

        try:
            response = query_engine.query(query)
            print("ğŸ’¡ å›ç­”:")
            print(response)

            if hasattr(response, 'source_nodes') and response.source_nodes:
                print("\nğŸ“š ç›¸å…³æ–‡æ¡£ç‰‡æ®µ:")
                for j, node in enumerate(response.source_nodes, 1):
                    print(f"\n  ç‰‡æ®µ {j} (ç›¸ä¼¼åº¦: {node.score:.4f}):")
                    print(f"  {node.text[:200]}...")

            print("\n" + "-" * 60)

        except Exception as e:
            print(f"âŒ æŸ¥è¯¢å¤±è´¥: {str(e)}")


def interactive_query(query_engine):
    """
    äº¤äº’å¼æŸ¥è¯¢å‡½æ•°

    Args:
        query_engine: æŸ¥è¯¢å¼•æ“å¯¹è±¡
    """
    print("\n" + "=" * 50)
    print("ğŸ“– PDF RAG äº¤äº’å¼æŸ¥è¯¢ç³»ç»Ÿ")
    print("=" * 50)
    print("è¾“å…¥ 'exit' æˆ– 'quit' é€€å‡º\n")

    while True:
        try:
            query = input("\nğŸ” è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ").strip()

            if query.lower() in ['exit', 'quit', 'é€€å‡º']:
                print("\nğŸ‘‹ å†è§ï¼")
                break

            if not query:
                continue

            print("\nğŸ’­ æ€è€ƒä¸­...\n")
            response = query_engine.query(query)

            print("ğŸ’¡ å›ç­”:")
            print(response)
            print("\n" + "-" * 50)

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            print(f"\nâŒ æŸ¥è¯¢å‡ºé”™: {str(e)}")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("PDF RAG ç³»ç»Ÿ - ä½¿ç”¨ BGE-M3 Embedding æ¨¡å‹")
    print("=" * 60)
    print()

    try:
        # 1. è®¾ç½® RAG ç³»ç»Ÿ
        print("æ­¥éª¤ 1/5: è®¾ç½® RAG ç³»ç»Ÿé…ç½®")
        setup_rag_system()
        print()

        # 2. åŠ è½½æ–‡æ¡£
        print("æ­¥éª¤ 2/5: åŠ è½½ PDF æ–‡æ¡£")
        documents = load_documents("./data/")
        if not documents:
            print("\nâš ï¸  è¯·å°† PDF æ–‡ä»¶æ”¾å…¥ ./data/ ç›®å½•åé‡æ–°è¿è¡Œ")
            return
        print()

        # 3. æ„å»ºç´¢å¼•
        print("æ­¥éª¤ 3/5: æ„å»ºå‘é‡ç´¢å¼•")
        index = build_index(documents, show_estimation=True)
        print()

        # 4. åˆ›å»ºæŸ¥è¯¢å¼•æ“
        print("æ­¥éª¤ 4/5: åˆ›å»ºæŸ¥è¯¢å¼•æ“")
        query_engine = create_query_engine(index, similarity_top_k=3)
        print()

        # 5. è¿è¡Œç¤ºä¾‹æŸ¥è¯¢
        print("æ­¥éª¤ 5/5: è¿è¡Œç¤ºä¾‹æŸ¥è¯¢")
        run_example_queries(query_engine)

        # 6. è¿›å…¥äº¤äº’å¼æŸ¥è¯¢
        print("\n" + "=" * 60)
        interactive_query(query_engine)

    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
